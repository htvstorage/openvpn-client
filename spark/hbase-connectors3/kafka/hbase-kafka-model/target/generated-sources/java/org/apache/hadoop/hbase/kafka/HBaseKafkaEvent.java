/**
 * Autogenerated by Avro
 * 
 * DO NOT EDIT DIRECTLY
 */
package org.apache.hadoop.hbase.kafka;  
@SuppressWarnings("all")
@org.apache.avro.specific.AvroGenerated
public class HBaseKafkaEvent extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"HBaseKafkaEvent\",\"namespace\":\"org.apache.hadoop.hbase.kafka\",\"fields\":[{\"name\":\"key\",\"type\":\"bytes\"},{\"name\":\"timestamp\",\"type\":\"long\"},{\"name\":\"delete\",\"type\":\"boolean\"},{\"name\":\"value\",\"type\":\"bytes\"},{\"name\":\"qualifier\",\"type\":\"bytes\"},{\"name\":\"family\",\"type\":\"bytes\"},{\"name\":\"table\",\"type\":\"bytes\"}]}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
  @Deprecated public java.nio.ByteBuffer key;
  @Deprecated public long timestamp;
  @Deprecated public boolean delete;
  @Deprecated public java.nio.ByteBuffer value;
  @Deprecated public java.nio.ByteBuffer qualifier;
  @Deprecated public java.nio.ByteBuffer family;
  @Deprecated public java.nio.ByteBuffer table;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>. 
   */
  public HBaseKafkaEvent() {}

  /**
   * All-args constructor.
   */
  public HBaseKafkaEvent(java.nio.ByteBuffer key, java.lang.Long timestamp, java.lang.Boolean delete, java.nio.ByteBuffer value, java.nio.ByteBuffer qualifier, java.nio.ByteBuffer family, java.nio.ByteBuffer table) {
    this.key = key;
    this.timestamp = timestamp;
    this.delete = delete;
    this.value = value;
    this.qualifier = qualifier;
    this.family = family;
    this.table = table;
  }

  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call. 
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return key;
    case 1: return timestamp;
    case 2: return delete;
    case 3: return value;
    case 4: return qualifier;
    case 5: return family;
    case 6: return table;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }
  // Used by DatumReader.  Applications should not call. 
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: key = (java.nio.ByteBuffer)value$; break;
    case 1: timestamp = (java.lang.Long)value$; break;
    case 2: delete = (java.lang.Boolean)value$; break;
    case 3: value = (java.nio.ByteBuffer)value$; break;
    case 4: qualifier = (java.nio.ByteBuffer)value$; break;
    case 5: family = (java.nio.ByteBuffer)value$; break;
    case 6: table = (java.nio.ByteBuffer)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  /**
   * Gets the value of the 'key' field.
   */
  public java.nio.ByteBuffer getKey() {
    return key;
  }

  /**
   * Sets the value of the 'key' field.
   * @param value the value to set.
   */
  public void setKey(java.nio.ByteBuffer value) {
    this.key = value;
  }

  /**
   * Gets the value of the 'timestamp' field.
   */
  public java.lang.Long getTimestamp() {
    return timestamp;
  }

  /**
   * Sets the value of the 'timestamp' field.
   * @param value the value to set.
   */
  public void setTimestamp(java.lang.Long value) {
    this.timestamp = value;
  }

  /**
   * Gets the value of the 'delete' field.
   */
  public java.lang.Boolean getDelete() {
    return delete;
  }

  /**
   * Sets the value of the 'delete' field.
   * @param value the value to set.
   */
  public void setDelete(java.lang.Boolean value) {
    this.delete = value;
  }

  /**
   * Gets the value of the 'value' field.
   */
  public java.nio.ByteBuffer getValue() {
    return value;
  }

  /**
   * Sets the value of the 'value' field.
   * @param value the value to set.
   */
  public void setValue(java.nio.ByteBuffer value) {
    this.value = value;
  }

  /**
   * Gets the value of the 'qualifier' field.
   */
  public java.nio.ByteBuffer getQualifier() {
    return qualifier;
  }

  /**
   * Sets the value of the 'qualifier' field.
   * @param value the value to set.
   */
  public void setQualifier(java.nio.ByteBuffer value) {
    this.qualifier = value;
  }

  /**
   * Gets the value of the 'family' field.
   */
  public java.nio.ByteBuffer getFamily() {
    return family;
  }

  /**
   * Sets the value of the 'family' field.
   * @param value the value to set.
   */
  public void setFamily(java.nio.ByteBuffer value) {
    this.family = value;
  }

  /**
   * Gets the value of the 'table' field.
   */
  public java.nio.ByteBuffer getTable() {
    return table;
  }

  /**
   * Sets the value of the 'table' field.
   * @param value the value to set.
   */
  public void setTable(java.nio.ByteBuffer value) {
    this.table = value;
  }

  /** Creates a new HBaseKafkaEvent RecordBuilder */
  public static org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder newBuilder() {
    return new org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder();
  }
  
  /** Creates a new HBaseKafkaEvent RecordBuilder by copying an existing Builder */
  public static org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder newBuilder(org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder other) {
    return new org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder(other);
  }
  
  /** Creates a new HBaseKafkaEvent RecordBuilder by copying an existing HBaseKafkaEvent instance */
  public static org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder newBuilder(org.apache.hadoop.hbase.kafka.HBaseKafkaEvent other) {
    return new org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder(other);
  }
  
  /**
   * RecordBuilder for HBaseKafkaEvent instances.
   */
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<HBaseKafkaEvent>
    implements org.apache.avro.data.RecordBuilder<HBaseKafkaEvent> {

    private java.nio.ByteBuffer key;
    private long timestamp;
    private boolean delete;
    private java.nio.ByteBuffer value;
    private java.nio.ByteBuffer qualifier;
    private java.nio.ByteBuffer family;
    private java.nio.ByteBuffer table;

    /** Creates a new Builder */
    private Builder() {
      super(org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.SCHEMA$);
    }
    
    /** Creates a Builder by copying an existing Builder */
    private Builder(org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.key)) {
        this.key = data().deepCopy(fields()[0].schema(), other.key);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.timestamp)) {
        this.timestamp = data().deepCopy(fields()[1].schema(), other.timestamp);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.delete)) {
        this.delete = data().deepCopy(fields()[2].schema(), other.delete);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.value)) {
        this.value = data().deepCopy(fields()[3].schema(), other.value);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.qualifier)) {
        this.qualifier = data().deepCopy(fields()[4].schema(), other.qualifier);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.family)) {
        this.family = data().deepCopy(fields()[5].schema(), other.family);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.table)) {
        this.table = data().deepCopy(fields()[6].schema(), other.table);
        fieldSetFlags()[6] = true;
      }
    }
    
    /** Creates a Builder by copying an existing HBaseKafkaEvent instance */
    private Builder(org.apache.hadoop.hbase.kafka.HBaseKafkaEvent other) {
            super(org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.SCHEMA$);
      if (isValidValue(fields()[0], other.key)) {
        this.key = data().deepCopy(fields()[0].schema(), other.key);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.timestamp)) {
        this.timestamp = data().deepCopy(fields()[1].schema(), other.timestamp);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.delete)) {
        this.delete = data().deepCopy(fields()[2].schema(), other.delete);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.value)) {
        this.value = data().deepCopy(fields()[3].schema(), other.value);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.qualifier)) {
        this.qualifier = data().deepCopy(fields()[4].schema(), other.qualifier);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.family)) {
        this.family = data().deepCopy(fields()[5].schema(), other.family);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.table)) {
        this.table = data().deepCopy(fields()[6].schema(), other.table);
        fieldSetFlags()[6] = true;
      }
    }

    /** Gets the value of the 'key' field */
    public java.nio.ByteBuffer getKey() {
      return key;
    }
    
    /** Sets the value of the 'key' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder setKey(java.nio.ByteBuffer value) {
      validate(fields()[0], value);
      this.key = value;
      fieldSetFlags()[0] = true;
      return this; 
    }
    
    /** Checks whether the 'key' field has been set */
    public boolean hasKey() {
      return fieldSetFlags()[0];
    }
    
    /** Clears the value of the 'key' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder clearKey() {
      key = null;
      fieldSetFlags()[0] = false;
      return this;
    }

    /** Gets the value of the 'timestamp' field */
    public java.lang.Long getTimestamp() {
      return timestamp;
    }
    
    /** Sets the value of the 'timestamp' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder setTimestamp(long value) {
      validate(fields()[1], value);
      this.timestamp = value;
      fieldSetFlags()[1] = true;
      return this; 
    }
    
    /** Checks whether the 'timestamp' field has been set */
    public boolean hasTimestamp() {
      return fieldSetFlags()[1];
    }
    
    /** Clears the value of the 'timestamp' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder clearTimestamp() {
      fieldSetFlags()[1] = false;
      return this;
    }

    /** Gets the value of the 'delete' field */
    public java.lang.Boolean getDelete() {
      return delete;
    }
    
    /** Sets the value of the 'delete' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder setDelete(boolean value) {
      validate(fields()[2], value);
      this.delete = value;
      fieldSetFlags()[2] = true;
      return this; 
    }
    
    /** Checks whether the 'delete' field has been set */
    public boolean hasDelete() {
      return fieldSetFlags()[2];
    }
    
    /** Clears the value of the 'delete' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder clearDelete() {
      fieldSetFlags()[2] = false;
      return this;
    }

    /** Gets the value of the 'value' field */
    public java.nio.ByteBuffer getValue() {
      return value;
    }
    
    /** Sets the value of the 'value' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder setValue(java.nio.ByteBuffer value) {
      validate(fields()[3], value);
      this.value = value;
      fieldSetFlags()[3] = true;
      return this; 
    }
    
    /** Checks whether the 'value' field has been set */
    public boolean hasValue() {
      return fieldSetFlags()[3];
    }
    
    /** Clears the value of the 'value' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder clearValue() {
      value = null;
      fieldSetFlags()[3] = false;
      return this;
    }

    /** Gets the value of the 'qualifier' field */
    public java.nio.ByteBuffer getQualifier() {
      return qualifier;
    }
    
    /** Sets the value of the 'qualifier' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder setQualifier(java.nio.ByteBuffer value) {
      validate(fields()[4], value);
      this.qualifier = value;
      fieldSetFlags()[4] = true;
      return this; 
    }
    
    /** Checks whether the 'qualifier' field has been set */
    public boolean hasQualifier() {
      return fieldSetFlags()[4];
    }
    
    /** Clears the value of the 'qualifier' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder clearQualifier() {
      qualifier = null;
      fieldSetFlags()[4] = false;
      return this;
    }

    /** Gets the value of the 'family' field */
    public java.nio.ByteBuffer getFamily() {
      return family;
    }
    
    /** Sets the value of the 'family' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder setFamily(java.nio.ByteBuffer value) {
      validate(fields()[5], value);
      this.family = value;
      fieldSetFlags()[5] = true;
      return this; 
    }
    
    /** Checks whether the 'family' field has been set */
    public boolean hasFamily() {
      return fieldSetFlags()[5];
    }
    
    /** Clears the value of the 'family' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder clearFamily() {
      family = null;
      fieldSetFlags()[5] = false;
      return this;
    }

    /** Gets the value of the 'table' field */
    public java.nio.ByteBuffer getTable() {
      return table;
    }
    
    /** Sets the value of the 'table' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder setTable(java.nio.ByteBuffer value) {
      validate(fields()[6], value);
      this.table = value;
      fieldSetFlags()[6] = true;
      return this; 
    }
    
    /** Checks whether the 'table' field has been set */
    public boolean hasTable() {
      return fieldSetFlags()[6];
    }
    
    /** Clears the value of the 'table' field */
    public org.apache.hadoop.hbase.kafka.HBaseKafkaEvent.Builder clearTable() {
      table = null;
      fieldSetFlags()[6] = false;
      return this;
    }

    @Override
    public HBaseKafkaEvent build() {
      try {
        HBaseKafkaEvent record = new HBaseKafkaEvent();
        record.key = fieldSetFlags()[0] ? this.key : (java.nio.ByteBuffer) defaultValue(fields()[0]);
        record.timestamp = fieldSetFlags()[1] ? this.timestamp : (java.lang.Long) defaultValue(fields()[1]);
        record.delete = fieldSetFlags()[2] ? this.delete : (java.lang.Boolean) defaultValue(fields()[2]);
        record.value = fieldSetFlags()[3] ? this.value : (java.nio.ByteBuffer) defaultValue(fields()[3]);
        record.qualifier = fieldSetFlags()[4] ? this.qualifier : (java.nio.ByteBuffer) defaultValue(fields()[4]);
        record.family = fieldSetFlags()[5] ? this.family : (java.nio.ByteBuffer) defaultValue(fields()[5]);
        record.table = fieldSetFlags()[6] ? this.table : (java.nio.ByteBuffer) defaultValue(fields()[6]);
        return record;
      } catch (Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }
}
